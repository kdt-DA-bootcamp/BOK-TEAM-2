{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import ast\n",
    "from gensim.models import FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('sepa_data_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'tagged'], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fast-text는 txt파일이어야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "df = pd.read_csv('sepa_data_3.csv')\n",
    "\n",
    "# 태깅 제거\n",
    "df['text'] = df['tagged'].apply(lambda x: ' '.join([word[0] for word in ast.literal_eval(x)]))\n",
    "\n",
    "# 텍스트 파일로 따로 저장해보자\n",
    "with open('cleaned_data.txt', 'w', encoding='utf-8') as f:\n",
    "    for text in df['text']:\n",
    "        f.write(text + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text 파일 읽기\n",
    "with open('cleaned_data.txt', 'r', encoding='utf-8') as f:\n",
    "    tokens = [line.strip().split() for line in f.readlines()] #리스트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "\n",
    "# 모델 학습\n",
    "model = FastText(\n",
    "    sentences=tokens,  # tokens는 텍스트 파일에서 읽은 단어 리스트여야 함\n",
    "    vector_size=128,\n",
    "    window=5,\n",
    "    min_count=5,\n",
    "    sg=1,\n",
    "    epochs=3\n",
    ")\n",
    "\n",
    "# 모델 저장\n",
    "model.save(\"fasttext_model1.bin\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 로드\n",
    "model = FastText.load(\"fasttext_model1.bin\")\n",
    "\n",
    "# 예시: 모델 사용\n",
    "print(model.wv[\"금리인상\"])  # 특정 단어 입력, FastText 모델은 복합단어 가능\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# 모델 학습 (skip-gram 방식으로 학습)\n",
    "model_word2vec = Word2Vec(\n",
    "    sentences=tokens,  \n",
    "    vector_size=128,\n",
    "    window=5,\n",
    "    min_count=5,\n",
    "    sg=1,  # skip-gram 방식 # n그램 설정하려면 따로 넣어줘야함.\n",
    "    epochs=3\n",
    ")\n",
    "\n",
    "# 모델 저장\n",
    "model_word2vec.save(\"word2vec_model1.bin\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 로드\n",
    "model = FastText.load(\"word2vec_model1.bin\")\n",
    "\n",
    "# 예시: 모델 사용\n",
    "print(model.wv[\"금리\",\"인상\"])  # word2vec에서는 복합 단어 사용이 안됨. 둘의 가장 큰 특징징\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 코사인 유사도 계싼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_vector = np.array([0.21913646, 0.22470665, -0.07289398, -0.8849918, -0.30110687, -0.1064557, 0.35088062, 0.5068087, -0.58582336, 0.48590612, 0.60888124, 0.0084481, 0.07368367, -0.14572962, -0.19897108, -0.62394506, 0.02652153, 0.18398927, 0.02256804, 0.08697208, -0.23649073, 0.17162246, 0.09170464, -0.05384137, 0.17058688, -0.0112307, -0.19562191, -0.6253643, 0.25034344, -0.16422908, 0.2386792, -0.21956538, -0.01778568, -0.41555953, 0.55859977, 0.18110102, 0.3145579, 0.56241536, -0.16971047, -0.07302298, -0.0407253, 0.13376787, 0.05373578, 0.10835387, 0.6127579, -0.09665617, -0.14878081, -0.30343792, -0.36431652, 0.01549789, 0.42319977, -0.27383843, -0.09855911, -0.28790295, -0.12521565, 0.6930875, 0.42314616, 0.08756365, -0.1132491, -0.2839753, 0.13114887, 0.09737734, 0.08863978, 0.0464404, -0.21889237, -0.203633, 0.02447037, -0.18083204, 0.22898382, -0.00712855, 0.18953162, -0.00762656, 0.0471206, 0.05759172, -0.32325536, -0.2639283, 0.0459367, 0.17608728, -0.27325603, 0.07330365, -0.33259428, -0.29980728, 0.02769291, 0.11966075, -0.04807175, -0.03551167, 0.17335652, 0.36047316, 0.6181729, 0.3837328, -0.25508058, 1.0757991, -0.5489129, -0.34103474, 0.03154385, -0.11571973, 0.0660311, 0.41600168, -0.01769333, -0.04328798, 0.02403822, 0.7303136, 0.48807478, -0.41337398, -0.37567413, -0.21682805, -0.20929685, -0.21350232, -0.07528502, -0.13037401, -0.08484555, 0.3793308, 0.0101695, -0.48670584, 0.14177121, -0.10923098, -0.03386141, 0.16982687, 0.03023274, -0.4693007, 0.20668176, 0.40010637, -0.61306936, 0.49048698, 0.29467085, 0.30415395, 0.13400489, 0.04522144])\n",
    "\n",
    "word2vec_vector = np.array([0.01265653, 0.0584195, -0.1899038, -0.78155655, -0.39691025, 0.13279244, 0.2933973, -0.03959981, -0.0544765, -0.13753077, -0.45713043, -0.04648737, -0.11307699, -0.51959383, 0.17811413, 0.30646643, -0.08413259, -0.1479467, 0.27420285, 0.01978832, -0.34508398, 0.5775325, -0.8053322, 0.01153104, -0.04498272, -0.4138773, -0.43424833, -0.03725495, 0.5535941, -0.1767404, -0.01173119, -0.05211203, 0.10247838, -0.11653896, 0.24283008, 0.41998112, 0.21705979, -0.04920039, -0.27606356, -0.01574518, -0.01428626, 0.5589667, -0.16947491, -0.36575785, 0.12295908, -0.03417638, -0.29662868, -0.58444333, 0.5883107, -0.20395157, 0.5373483, -0.24650347, 0.43312243, -0.35518605, 0.00601155, 0.40532988, 0.7191061, 0.35167426, -0.10335038, -0.24853027, -0.35286903, 0.07114995, -0.0373207, 0.16623533, 0.08904121, 0.25221583, 0.28868434, -0.32141253, 0.5217322, 0.12813193, 0.14549135, -0.51050776, -0.622984, 0.2993441, 0.30792966, -0.08419362, 0.15949227, -0.44576123, 0.06436826, 0.6297215, 0.54523164, -0.2815274, -0.24737187, 0.03351562, 0.00356279, 0.57120955, -0.1921696, 0.2598943, 0.14277112, 0.49643323, 0.12963405, -0.64099306, 0.09321833, -0.00967596, -0.37836778, 0.03365781, -0.6794552, 0.03295646, -0.53395474, -0.23416679, -0.00935362, -0.00249847, 0.03526085, -0.00811672, 0.1399557, 0.02251391, -0.2281758, -0.05065441, -0.2183643, -0.34131137, -0.03789137, 0.13806428, 0.15418814, -0.60366005, -0.12660027, -1.0220213, -0.17279315, -0.09593229, -0.37430033, -0.02727003, 0.03535508, -0.45351446, -0.41327912, 0.25726497, 0.4127551, 0.03193324, 0.4038561, 0.37234524])\n",
    "\n",
    "# 코사인 유사도 계산\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cosine_sim = cosine_similarity([fasttext_vector], [word2vec_vector])\n",
    "\n",
    "print(\"Cosine Similarity:\", cosine_sim[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastText 모델에서 '금리인상'과 '금리하락'의 코사인 유사도: 0.9724056124687195\n",
      "Word2Vec 모델에서 '금리'와 '인상', '금리'와 '하락'의 코사인 유사도: 0.7950236797332764\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import FastText, Word2Vec\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# 모델 불러오기\n",
    "fasttext_model = FastText.load(\"fasttext_model1.bin\")\n",
    "word2vec_model = Word2Vec.load(\"word2vec_model1.bin\")\n",
    "\n",
    "# FastText 모델에서 벡터 추출\n",
    "fasttext_vector_apple = fasttext_model.wv['금리인상']\n",
    "fasttext_vector_banana = fasttext_model.wv['금리하락']\n",
    "\n",
    "# Word2Vec 모델에서 '금리'와 '인상', '금리'와 '하락' 벡터를 각각 추출\n",
    "word2vec_vector_apple = word2vec_model.wv['금리'] + word2vec_model.wv['인상']  # 벡터 합성\n",
    "word2vec_vector_banana = word2vec_model.wv['금리'] + word2vec_model.wv['하락']  # 벡터 합성\n",
    "\n",
    "# 유사도 계산 (Cosine Similarity)\n",
    "cosine_sim_fasttext = cosine_similarity([fasttext_vector_apple], [fasttext_vector_banana])[0][0]\n",
    "cosine_sim_word2vec = cosine_similarity([word2vec_vector_apple], [word2vec_vector_banana])[0][0]\n",
    "\n",
    "# 출력\n",
    "print(f\"FastText 모델에서 '금리인상'과 '금리하락'의 코사인 유사도: {cosine_sim_fasttext}\")\n",
    "print(f\"Word2Vec 모델에서 '금리'와 '인상', '금리'와 '하락'의 코사인 유사도: {cosine_sim_word2vec}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 참고 교재\n",
    "\n",
    "#### 파이토치 트랜스포머를 활용한 자연어 처리와 컴터비전 .....\n",
    "\n",
    "#### p.269 ~ 301\n",
    "\n",
    "#### p.299 FastText 장점 부각"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
