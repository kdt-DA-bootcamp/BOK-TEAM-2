{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예진ver 문장 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [date, sentences]\n",
      "Index: [] Empty DataFrame\n",
      "Columns: [date, sentences]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from kiwipiepy import Kiwi\n",
    "kiwi = Kiwi()\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def remove_policy_date(text):\n",
    "    # \"통화정책방향 (YYYY. M. D.)\" 또는 \"통화정책방향 (YYYY. M. D)\" 패턴 제거\n",
    "    pattern = r\"통화정책방향\\s*\\(\\d{4}\\.\\s*\\d{1,2}\\.\\s*\\d{1,2}\\.?\\)\"\n",
    "    clean_text = re.sub(pattern, \"\", text).strip()\n",
    "    return clean_text\n",
    "data_folder = r'C:\\Users\\yoons\\Desktop\\금리예측포르젝트\\test\\병합할파일\\기자회견테스트폴더\\conferences_sentences.csv'\n",
    "data_files = glob.glob(os.path.join(data_folder, '*.txt'))\n",
    "\n",
    "dates = []\n",
    "sentences = []\n",
    "\n",
    "for d in data_files:\n",
    "    f = open(d, encoding='utf-8')\n",
    "    data = f.read()\n",
    "\n",
    "    # 각 문서에서 날짜 뽑아내기 (형식 일정)\n",
    "    date_match = re.findall(r'(\\d{4}).\\s*(\\d{1,2}).\\s*(\\d{1,2})', data)\n",
    "\n",
    "    if date_match :\n",
    "        year, month, day = date_match[0]  # 첫 번째 매치만 사용\n",
    "        if len(month) == 1 :\n",
    "            month = '0' + month\n",
    "        if len(day) == 1 :\n",
    "            day = '0' + day\n",
    "        date_f = f\"{year}-{month}-{day}\"\n",
    "        print(date_f) # 정상적으로 출력되는 것 확인 가능\n",
    "    else:\n",
    "        date_f = \"날짜 없음\"\n",
    "    dates.append(date_f)\n",
    "\n",
    "    data = remove_policy_date(data)\n",
    "    # 텍스트에서는 특수문자 □ 제거\n",
    "    data = data.replace('□','')\n",
    "    data = data.replace('\\n', '')\n",
    "\n",
    "    # 나머지는 Kiwi 이용해서 문장 토큰화시킨 담에 df 저장하기 \n",
    "    sents = [s.text for s in kiwi.split_into_sents(data)]\n",
    "    sentences.append(sents)\n",
    "\n",
    "df_sentences = pd.DataFrame({'date':dates, \n",
    "                             'sentences':sentences})\n",
    "# 정렬: 오름차순\n",
    "df_sentences = df_sentences.sort_values('date', ignore_index=True)\n",
    "# 중복값 제거 \n",
    "df_sentences = df_sentences.drop_duplicates(subset=['date'], ignore_index=True)\n",
    "\n",
    "print(df_sentences.head(10), df_sentences.tail(10))\n",
    "\n",
    "df_sentences.to_csv(r'C:\\Users\\yoons\\Desktop\\금리예측포르젝트\\test\\병합할파일\\기자회견테스트폴더\\conferences_sentences.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 디버깅 포함(기자회견 text > 내 사전과 test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨링 결과 (상위 5개):\n",
      "   Unnamed: 0        date                                          sentences  \\\n",
      "0           0  2009-04-09  ['금융통화위원회는 다음 통화정책방향 결정시까지 한국은행 기준금리를 현 수준(2.0...   \n",
      "1           1  2009-05-12  ['금융통화위원회는 다음 통화정책방향 결정시까지 한국은행 기준금리를 현 수준(2.0...   \n",
      "2           2  2009-06-11  ['금융통화위원회는 다음 통화정책방향 결정시까지 한국은행기준금리를 현 수준(2.00...   \n",
      "3           3  2009-07-09  ['금융통화위원회는 다음 통화정책방향 결정시까지 한국은행기준금리를 현 수준(2.00...   \n",
      "4           4  2009-08-11  ['금융통화위원회는 다음 통화정책방향 결정시까지 한국은행기준금리를 현 수준(2.00...   \n",
      "\n",
      "     label  \n",
      "0  neutral  \n",
      "1  neutral  \n",
      "2  neutral  \n",
      "3  neutral  \n",
      "4  neutral  \n",
      "라벨링된 결과가 conferences_labeled.csv에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast  # 문자열 리스트를 파싱하기 위해 필요\n",
    "\n",
    "# 사전 파일 로드 (파일 경로 확인 필요)\n",
    "try:\n",
    "    hawkish_df = pd.read_csv('final_hawkish.csv', encoding='utf-8')\n",
    "    dovish_df = pd.read_csv('final_dovish.csv', encoding='utf-8')\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"파일을 찾을 수 없습니다: {e}\")\n",
    "    exit()\n",
    "\n",
    "# 매파적과 비둘기파적 단어 리스트 (컬럼 이름 확인 필요)\n",
    "try:\n",
    "    hawkish_keywords = hawkish_df['Hawkish'].tolist()  # 'Hawkish' 컬럼\n",
    "    dovish_keywords = dovish_df['Dovish'].tolist()    # 'Dovish' 컬럼\n",
    "except KeyError as e:\n",
    "    print(f\"컬럼 이름 오류: {e}\")\n",
    "    print(\"hawkish_df 컬럼:\", hawkish_df.columns)\n",
    "    print(\"dovish_df 컬럼:\", dovish_df.columns)\n",
    "    exit()\n",
    "\n",
    "# 기자회견 문서 파일 로드\n",
    "try:\n",
    "    conferences_df = pd.read_csv('conferences_sentences.csv', encoding='utf-8')\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"파일을 찾을 수 없습니다: {e}\")\n",
    "    exit()\n",
    "\n",
    "# 문장 데이터가 제대로 있는지 확인\n",
    "if 'sentences' not in conferences_df.columns:\n",
    "    print(\"conferences_sentences.csv에 'sentences' 컬럼이 없습니다.\")\n",
    "    print(\"conferences_df 컬럼:\", conferences_df.columns)\n",
    "    exit()\n",
    "\n",
    "# 라벨링 함수 (토큰화된 데이터 활용)\n",
    "def label_sentence(tokens, hawkish_keywords, dovish_keywords):\n",
    "    # 토큰이 문자열로 저장된 리스트라면 파싱 (예: \"[금리, 인상, 예상]\" -> 리스트로 변환)\n",
    "    if isinstance(tokens, str):\n",
    "        try:\n",
    "            # 문자열 리스트를 실제 리스트로 변환\n",
    "            tokens = ast.literal_eval(tokens)\n",
    "        except (ValueError, SyntaxError):\n",
    "            # 파싱 실패 시 공백 기준으로 단순 분리\n",
    "            tokens = tokens.split()\n",
    "    \n",
    "    # 토큰이 리스트가 아닌 경우 처리\n",
    "    if not isinstance(tokens, list):\n",
    "        return 'neutral'\n",
    "    \n",
    "    # 매파적과 비둘기파적 키워드 매칭\n",
    "    hawkish_count = sum(1 for word in hawkish_keywords if word in tokens)\n",
    "    dovish_count = sum(1 for word in dovish_keywords if word in tokens)\n",
    "    \n",
    "    # 매파적과 비둘기파적 키워드를 비교하여 라벨링\n",
    "    if hawkish_count > dovish_count:\n",
    "        return 'hawkish'\n",
    "    elif dovish_count > hawkish_count:\n",
    "        return 'dovish'\n",
    "    else:\n",
    "        return 'neutral'  # 비슷하게 등장하거나 모두 없는 경우는 중립\n",
    "\n",
    "# 문서의 각 문장에 라벨링 적용\n",
    "conferences_df['label'] = conferences_df['sentences'].apply(\n",
    "    lambda tokens: label_sentence(tokens, hawkish_keywords, dovish_keywords)\n",
    ")\n",
    "\n",
    "# 결과 확인\n",
    "print(\"라벨링 결과 (상위 5개):\")\n",
    "print(conferences_df.head())\n",
    "\n",
    "# 결과를 새로운 CSV 파일로 저장\n",
    "output_file = 'conferences_labeled.csv'\n",
    "conferences_df.to_csv(output_file, encoding='utf-8-sig', index=False)\n",
    "print(f\"라벨링된 결과가 {output_file}에 저장되었습니다.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
