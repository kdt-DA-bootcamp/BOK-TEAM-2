{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Dn5HIuaO8c9N"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "import ast\n",
        "from gensim.models import FastText"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqRVn7YK8c9Q"
      },
      "outputs": [],
      "source": [
        "# df = pd.read_csv('cleaned_data_keywords.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GTiKzh0u8c9Q",
        "outputId": "ea35f357-7b7e-4f67-d12e-2de736c4c418"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['date', 'sentences'], dtype='object')"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUJwNLZo8c9S"
      },
      "source": [
        "### Fast-text는 txt파일이어야함"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yKP3KKQ48c9T"
      },
      "outputs": [],
      "source": [
        "# 문장 변환\n",
        "import pandas as pd\n",
        "import ast\n",
        "\n",
        "# 데이터 불러오기\n",
        "df = pd.read_csv('hk_sentences_1.csv')\n",
        "\n",
        "# 'sentences' 칼럼에서 태깅을 제거하고 단어만 추출 (태그 분리)\n",
        "df['text'] = df['sentences'].apply(lambda x: ' '.join([word.split('/')[0] for word in ast.literal_eval(x)]))\n",
        "\n",
        "# 텍스트 파일로 저장\n",
        "with open('hk_sentences.txt', 'w', encoding='utf-8') as f:\n",
        "    for text in df['text']:\n",
        "        f.write(text + '\\n')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0FdTxsNx8c9T"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import ast\n",
        "\n",
        "df = pd.read_csv('hk_sentences_1.csv')\n",
        "\n",
        "# 태깅 제거\n",
        "df['text'] = df['sentences'].apply(lambda x: ' '.join([word[0] for word in ast.literal_eval(x)]))\n",
        "\n",
        "# 텍스트 파일로 따로 저장해보자\n",
        "with open('hk_sentences.txt', 'w', encoding='utf-8') as f:\n",
        "    for text in df['text']:\n",
        "        f.write(text + '\\n')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### n그램 내장함수? 편하다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9-JHFJl8c9U"
      },
      "outputs": [],
      "source": [
        "# text 파일 읽기\n",
        "with open('/content/sample_data/cleaned_data_keywords.txt', 'r', encoding='utf-8') as f:\n",
        "    tokens = [line.strip().split() for line in f.readlines()] #리스트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E9aAMX4I8c9U"
      },
      "outputs": [],
      "source": [
        "from gensim.models import FastText\n",
        "\n",
        "# 학습\n",
        "model = FastText(\n",
        "    sentences=tokens,  # tokens는 텍스트 파일에서 읽은 단어 리스트여야 함\n",
        "    vector_size=300, \n",
        "    window=5,\n",
        "    min_count=25,\n",
        "    sg=1,\n",
        "    epochs=3,\n",
        "    min_n=1,\n",
        "    max_n=5,\n",
        "    negative=5\n",
        ")\n",
        "\n",
        "# 모델 저장\n",
        "model.save(\"업데이트.bin\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 순도 높은 사전을 얻지 못한 것 같다. \n",
        "    -(논문 그대로)\n",
        "    vector_size=128 > 300으로 늘려버리기 > 메모리 과부하\n",
        "    min_n=1 ~ max_n=5 (n그램)\n",
        "    negative= 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JBWGuR58c9U",
        "outputId": "0bb27707-0e1a-4d9f-a029-25c9cfed89d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 0.28488445 -0.3065864   0.0548155  -0.00822149  0.07313827  0.15408309\n",
            " -0.14688192  0.13730937  0.03785319  0.01474491 -0.15732452  0.22435066\n",
            " -0.07345411  0.27354822 -0.10147103  0.02262285 -0.00062848 -0.12988651\n",
            " -0.1522029  -0.0818905   0.18118075  0.2066023   0.02247971 -0.08116864\n",
            " -0.22655866  0.16399886 -0.13758014 -0.34404016  0.39889205  0.13880464\n",
            "  0.4040078  -0.01741497  0.31090698 -0.03572432 -0.14591941  0.07354025\n",
            "  0.04738261 -0.09606393 -0.03362769  0.20676804 -0.21234478 -0.08590214\n",
            " -0.07912035 -0.0200071   0.22323547  0.1599033  -0.10702426  0.23773159\n",
            " -0.01360496  0.19907564  0.09832553 -0.12158774 -0.02985627  0.14041013\n",
            " -0.16591775 -0.01259443 -0.04550545 -0.11344734  0.01583545  0.01595455\n",
            " -0.04837182 -0.25290856 -0.10143162 -0.05382365 -0.10247338 -0.06948587\n",
            " -0.18525155  0.2576035  -0.11511842  0.30417836  0.03564642 -0.21197245\n",
            "  0.14050514 -0.02361164 -0.05550092 -0.20660576  0.1909718  -0.0184369\n",
            " -0.11083558 -0.00177996 -0.10392036  0.30232647 -0.08172517  0.1391308\n",
            "  0.23287174 -0.15636179  0.08406408  0.08724281 -0.06611913 -0.3575709\n",
            " -0.13725378  0.1212366  -0.10054784  0.18188164  0.06075605  0.09016028\n",
            "  0.06630304  0.02086462 -0.31721067 -0.2775335  -0.08299728 -0.1657579\n",
            " -0.25764155  0.00695985  0.02504273  0.00338977  0.1136819   0.14025846\n",
            " -0.06752158 -0.07929918 -0.05598864 -0.221412   -0.04311691  0.29564947\n",
            " -0.19849549  0.0854973   0.27861375  0.01760551  0.17819148 -0.32854354\n",
            "  0.3562412  -0.12354681 -0.03348752 -0.07280166  0.14637147 -0.06620399\n",
            "  0.15260798  0.16547984 -0.15817307 -0.12719387 -0.17213832 -0.09813333\n",
            " -0.03801958 -0.04630689  0.02422084 -0.19811149 -0.04993743  0.00301024\n",
            "  0.11226083 -0.16571127 -0.08309228 -0.19745326 -0.01696887  0.1022571\n",
            "  0.07188285 -0.02149393  0.06506261 -0.33083436  0.1603742  -0.09611682\n",
            "  0.1454841  -0.124423    0.00489441 -0.03320791  0.10402691  0.05674923\n",
            "  0.35408682  0.12729868 -0.15950099 -0.04376328  0.30274898  0.19026963\n",
            "  0.00730309  0.15279096  0.29691777 -0.11697027  0.40034896  0.16128474\n",
            "  0.29766962 -0.00880268  0.26618308  0.10593289  0.0088269   0.09431979\n",
            "  0.1173006   0.18934363 -0.03646777  0.15290025 -0.1529431   0.0622382\n",
            "  0.04005007  0.16159044 -0.00477353 -0.02832212 -0.13774964 -0.08963836\n",
            "  0.06409638  0.07227141 -0.23683766 -0.17301172 -0.10443336  0.02388231\n",
            " -0.04972438 -0.13560843 -0.20520358 -0.0832509   0.02700936  0.0046794\n",
            " -0.12414762 -0.14416607 -0.10694771  0.12611939 -0.15017527 -0.1728328\n",
            " -0.12161756 -0.21944126 -0.11633955  0.21962492 -0.2442343  -0.11715754\n",
            " -0.39789087  0.05853529 -0.11334755 -0.15001427  0.13377137 -0.03003571\n",
            " -0.22386684 -0.19553423 -0.00315804  0.02169829  0.02807108 -0.19542259\n",
            " -0.02073375 -0.05261286 -0.02670723  0.04605014 -0.06736948 -0.23334132\n",
            "  0.03943794 -0.30672565 -0.10816853  0.16817948 -0.13889419 -0.02386035\n",
            " -0.13478327 -0.16831177  0.07661085  0.24924247  0.058263    0.16379513\n",
            " -0.17104666  0.00470693 -0.07393703  0.05887616  0.07362613  0.22677128\n",
            " -0.17467225 -0.11494221 -0.1664848  -0.08929934 -0.02770837  0.06004225\n",
            "  0.10052413 -0.12611265  0.07913184  0.12100817  0.0049316  -0.16980211\n",
            "  0.04378342 -0.13907602  0.05697453 -0.13247591 -0.07652467 -0.12919568\n",
            " -0.21132359 -0.11394303  0.25899208 -0.1803078  -0.10894961  0.07377195\n",
            "  0.19433032  0.06991132  0.1651296   0.06121813 -0.00794475 -0.09832612\n",
            " -0.10007998  0.36265054 -0.04374044  0.04115653  0.00692928 -0.1212509\n",
            "  0.13570775  0.02191778 -0.30055827  0.06380738  0.09452787  0.01239365\n",
            " -0.2899896  -0.2227726  -0.07008255 -0.04569449 -0.14031482  0.27338222\n",
            "  0.11799482 -0.3048469   0.12983865  0.0717481   0.02586661  0.05534098]\n"
          ]
        }
      ],
      "source": [
        "# 모델 로드\n",
        "model = FastText.load(\"업데이트.bin\")\n",
        "\n",
        "# 예시: 모델 사용\n",
        "print(model.wv[\"금리인상\"])  # 특정 단어 입력, FastText 모델은 복합단어 가능\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObtU3GmX8c9V"
      },
      "source": [
        "### 벡터"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W7I07djU8c9W",
        "outputId": "d09efbca-2113-49e2-bd09-77925c6ed89d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FastText 모델에서 '금리인상'과 '매파'의 코사인 유사도: 0.43686261773109436\n"
          ]
        }
      ],
      "source": [
        "from gensim.models import FastText, Word2Vec\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "#모델 부르기\n",
        "fasttext_model = FastText.load(\"업데이트.bin\")\n",
        "\n",
        "\n",
        "# 예시 단어 벡터 추출\n",
        "fasttext_vector_1 = fasttext_model.wv['금리인하']\n",
        "fasttext_vector_2 = fasttext_model.wv['매파']\n",
        "\n",
        "\n",
        "# 유사도 계산 (Cosine Similarity)\n",
        "cosine_sim_fasttext = cosine_similarity([fasttext_vector_1], [fasttext_vector_2])[0][0]\n",
        "\n",
        "# 출력\n",
        "print(f\"FastText 모델에서 '금리인상'과 '매파'의 코사인 유사도: {cosine_sim_fasttext}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MX1qRAgj8c9W",
        "outputId": "24b43d36-9383-4a95-bb61-3717c002430e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "FastText 모델에서 '금리인상'과 '매파'의 코사인 유사도: 0.5579149723052979\n"
          ]
        }
      ],
      "source": [
        "from gensim.models import FastText, Word2Vec\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "fasttext_model = FastText.load(\"전체.bin\")\n",
        "fasttext_vector_apple = fasttext_model.wv['인상']\n",
        "fasttext_vector_banana = fasttext_model.wv['비둘기파']\n",
        "cosine_sim_fasttext = cosine_similarity([fasttext_vector_apple], [fasttext_vector_banana])[0][0]\n",
        "print('인상' in fasttext_model.wv.key_to_index)\n",
        "print('비둘기파' in fasttext_model.wv.key_to_index)\n",
        "print(f\"FastText 모델에서 '금리인상'과 '매파'의 코사인 유사도: {cosine_sim_fasttext}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCf1fxj3GWBt",
        "outputId": "41f7f03d-3b91-4294-bc80-87aec9a259d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.0980782008403298\n"
          ]
        }
      ],
      "source": [
        "from gensim.models import FastText\n",
        "\n",
        "model_path = \"업데이트.bin\"  # 정확한 파일 경로 입력\n",
        "model = FastText.load(model_path)  # 모델 불러오기\n",
        "import numpy as np\n",
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "# 감성 단어 리스트 (예제)\n",
        "hawkish_words = [\n",
        "    \"강경\", \"공격적\", \"제재\", \"압박\", \"보복\", \"군사\", \"대응\", \"대립\", \"분쟁\", \"전쟁\", \"위험\", \"자극\",\n",
        "    \"불안\", \"위기\", \"공격\", \"반격\", \"저항\", \"독재\", \"억제\", \"억압\", \"단호\", \"무력\", \"충돌\", \"전술\",\n",
        "    \"철강\", \"경제적 압박\", \"무역전쟁\", \"대립각\", \"강경책\", \"복수\", \"강력한\", \"신속한\", \"도발\", \"세력\", \"공격적인\"\n",
        "]\n",
        "\n",
        "dovish_words = [\n",
        "    \"평화\", \"협력\", \"완화\", \"타협\", \"외교\", \"대화\", \"조정\", \"중재\", \"합의\", \"화해\", \"안정\", \"협상\",\n",
        "    \"협약\", \"교류\", \"관계\", \"회담\", \"평화적\", \"소통\", \"융화\", \"유화\", \"국제적\", \"상호이해\", \"신뢰\",\n",
        "    \"공동체\", \"존중\", \"연대\", \"공존\", \"구호\", \"공동선\", \"평화주의\", \"유연한\", \"지속적\", \"소극적\", \"융통성\",\n",
        "    \"친선\", \"구속력\", \"구속적\"\n",
        "]\n",
        "\n",
        "# 단어 임베딩 벡터 평균 구하기\n",
        "def get_average_vector(words, model):\n",
        "    vectors = [model.wv[word] for word in words if word in model.wv]\n",
        "    return np.mean(vectors, axis=0) if vectors else None\n",
        "\n",
        "hawkish_vector = get_average_vector(hawkish_words, model)\n",
        "dovish_vector = get_average_vector(dovish_words, model)\n",
        "\n",
        "# 감성 점수 계산 함수\n",
        "def get_polarity_score(word, model, hawkish_vector, dovish_vector):\n",
        "    if word not in model.wv:\n",
        "        return None\n",
        "\n",
        "    word_vector = model.wv[word]\n",
        "    hawkish_sim = 1 - cosine(word_vector, hawkish_vector)\n",
        "    dovish_sim = 1 - cosine(word_vector, dovish_vector)\n",
        "\n",
        "    return hawkish_sim / dovish_sim  # 비율 기반 극성 점수\n",
        "\n",
        "# 테스트 실행\n",
        "test_word = \"비둘기파\"\n",
        "print(get_polarity_score(test_word, model, hawkish_vector, dovish_vector))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 부트스트래핑 반복"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOl4ok4bHxT6",
        "outputId": "87e16472-c0f1-4813-8c48-0279788e99ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "부트스트래핑 평균 극성 점수: 0.987\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "# 감성 단어 리스트\n",
        "hawkish_words = [\n",
        "    \"강경\", \"공격적\", \"제재\", \"압박\", \"보복\", \"군사\", \"대응\", \"대립\", \"분쟁\", \"전쟁\", \"위험\", \"자극\",\n",
        "    \"불안\", \"위기\", \"공격\", \"반격\", \"저항\", \"독재\", \"억제\", \"억압\", \"단호\", \"무력\", \"충돌\", \"전술\",\n",
        "    \"철강\", \"경제적 압박\", \"무역전쟁\", \"대립각\", \"강경책\", \"복수\", \"강력한\", \"신속한\", \"도발\", \"세력\", \"공격적인\"\n",
        "]\n",
        "\n",
        "dovish_words = [\n",
        "    \"평화\", \"협력\", \"완화\", \"타협\", \"외교\", \"대화\", \"조정\", \"중재\", \"합의\", \"화해\", \"안정\", \"협상\",\n",
        "    \"협약\", \"교류\", \"관계\", \"회담\", \"평화적\", \"소통\", \"융화\", \"유화\", \"국제적\", \"상호이해\", \"신뢰\",\n",
        "    \"공동체\", \"존중\", \"연대\", \"공존\", \"구호\", \"공동선\", \"평화주의\", \"유연한\", \"지속적\", \"소극적\", \"융통성\",\n",
        "    \"친선\", \"구속력\", \"구속적\"\n",
        "]\n",
        "\n",
        "# 감성 단어를 10개의 하위 집합으로 분할\n",
        "hawkish_subsets = np.array_split(hawkish_words, 10)\n",
        "dovish_subsets = np.array_split(dovish_words, 10)\n",
        "\n",
        "# 부트스트래핑(랜덤 샘플링) 50회 반복\n",
        "boot_polarity_scores = []\n",
        "\n",
        "for _ in range(1000):\n",
        "    # 랜덤 하위 집합 선택\n",
        "    hawkish_sample = np.random.choice(hawkish_words, size=len(hawkish_words)//2, replace=False)\n",
        "    dovish_sample = np.random.choice(dovish_words, size=len(dovish_words)//2, replace=False)\n",
        "\n",
        "    # 감성 벡터 업데이트\n",
        "    hawkish_vector = get_average_vector(hawkish_sample, model)\n",
        "    dovish_vector = get_average_vector(dovish_sample, model)\n",
        "\n",
        "    # 특정 단어 감성 점수 계산 \n",
        "    test_word = \"인하\"\n",
        "    score = get_polarity_score(test_word, model, hawkish_vector, dovish_vector)\n",
        "\n",
        "    if score is not None:\n",
        "        boot_polarity_scores.append(score)\n",
        "\n",
        "# 평균 감성 점수 출력\n",
        "final_polarity_score = np.mean(boot_polarity_scores)\n",
        "print(f\"부트스트래핑 평균 극성 점수: {final_polarity_score:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 말도 안되는 점수에 재수정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "from gensim.models import FastText\n",
        "import numpy as np\n",
        "\n",
        "model = FastText.load(\"업데이트.bin\")\n",
        "hawkish_words = [\n",
        "    \"강경\", \"공격적\", \"제재\", \"압박\", \"보복\", \"군사\", \"대응\", \"대립\", \"분쟁\", \"전쟁\",\n",
        "    \"위험\", \"자극\", \"불안\", \"위기\", \"공격\", \"반격\", \"저항\", \"독재\", \"억제\", \"억압\",\n",
        "    \"단호\", \"무력\", \"충돌\", \"전술\", \"긴축\", \"인상\", \"상승\", \"팽창\", \"성장\", \"투기\",\n",
        "    \"상회\", \"광려\", \"확장\", \"상방\", \"흑자\", \"견조\", \"낙관\", \"매파\", \"변동성 감소\",\n",
        "    \"금리 상승\", \"물가 상승\", \"인플레이션 압력\", \"위험 선호\", \"채권 가격 하락\", \"요금 인상\",\n",
        "    \"부동산 가격 상승\"\n",
        "]\n",
        "\n",
        "dovish_words = [\n",
        "    \"평화\", \"협력\", \"완화\", \"타협\", \"외교\", \"대화\", \"조정\", \"중재\", \"합의\", \"화해\",\n",
        "    \"안정\", \"협상\", \"협약\", \"교류\", \"관계\", \"회담\", \"소통\", \"융화\", \"유화\", \"신뢰\",\n",
        "    \"공존\", \"존중\", \"연대\", \"인하\", \"둔화\", \"하락\", \"감소\", \"위축\", \"침체\", \"하회\",\n",
        "    \"비둘기\", \"하방\", \"적자\", \"부진\", \"비관\", \"변동성 확대\", \"금리 하락\", \"물가 하락\",\n",
        "    \"위험 회피\", \"채권 가격 상승\", \"요금 인하\", \"부동산 가격 하락\"\n",
        "]\n",
        "\n",
        "def bootstrap_lexicon(seed_words, model, iterations=50, subset_size=10):\n",
        "    expanded_lexicon = set(seed_words)\n",
        "    for _ in range(iterations):\n",
        "        subset = random.sample(seed_words, min(subset_size, len(seed_words)))\n",
        "        subset_vector = get_average_vector(subset, model)\n",
        "        similar_words = model.wv.most_similar(positive=[subset_vector], topn=10)\n",
        "        expanded_lexicon.update([word for word, _ in similar_words])\n",
        "    return expanded_lexicon\n",
        "\n",
        "hawkish_expanded = bootstrap_lexicon(hawkish_words, model)\n",
        "dovish_expanded = bootstrap_lexicon(dovish_words, model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 매파 비둘기파 나눠버리기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_polarity_lexicon(model, hawkish_seeds, dovish_seeds):\n",
        "    hawkish_lexicon = []\n",
        "    dovish_lexicon = []\n",
        "    for word in model.wv.index_to_key:\n",
        "        score = sentiment_propagation(word, model, hawkish_seeds, dovish_seeds)\n",
        "        if score > 1.1:\n",
        "            hawkish_lexicon.append(word)\n",
        "        elif score < 0.9:\n",
        "            dovish_lexicon.append(word)\n",
        "    return hawkish_lexicon, dovish_lexicon\n",
        "\n",
        "hawkish_lexicon, dovish_lexicon = build_polarity_lexicon(model, hawkish_words, dovish_words)\n",
        "print(f\"Hawkish words: {len(hawkish_lexicon)}, Dovish words: {len(dovish_lexicon)}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
