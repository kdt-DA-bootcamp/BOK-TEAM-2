{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 자료 구조 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['title', 'contents', 'date'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 파일 로드\n",
    "file_path = \"2010to2025_results.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# 컬럼 이름 출력\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['contents', 'tokens'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # CSV 파일 로드\n",
    "# file_path = \"processed_data.csv\"\n",
    "# df = pd.read_csv(file_path)\n",
    "\n",
    "# # 컬럼 이름 출력\n",
    "# print(df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기본"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "BrokenProcessPool",
     "evalue": "A child process terminated abruptly, the process pool is not usable anymore",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBrokenProcessPool\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 39\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# 병렬 처리로 텍스트 처리\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ProcessPoolExecutor() \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m---> 39\u001b[0m     contents_tagged \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(executor\u001b[38;5;241m.\u001b[39mmap(process_content, korea[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontents\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# 처리된 결과를 DataFrame에 추가\u001b[39;00m\n\u001b[0;32m     42\u001b[0m korea[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtagged\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m contents_tagged\n",
      "File \u001b[1;32mc:\\Users\\yoons\\anaconda3\\Lib\\concurrent\\futures\\process.py:859\u001b[0m, in \u001b[0;36mProcessPoolExecutor.map\u001b[1;34m(self, fn, timeout, chunksize, *iterables)\u001b[0m\n\u001b[0;32m    856\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchunksize must be >= 1.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 859\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mmap(partial(_process_chunk, fn),\n\u001b[0;32m    860\u001b[0m                       _get_chunks(\u001b[38;5;241m*\u001b[39miterables, chunksize\u001b[38;5;241m=\u001b[39mchunksize),\n\u001b[0;32m    861\u001b[0m                       timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    862\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _chain_from_iterable_of_lists(results)\n",
      "File \u001b[1;32mc:\\Users\\yoons\\anaconda3\\Lib\\concurrent\\futures\\_base.py:608\u001b[0m, in \u001b[0;36mExecutor.map\u001b[1;34m(self, fn, timeout, chunksize, *iterables)\u001b[0m\n\u001b[0;32m    605\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    606\u001b[0m     end_time \u001b[38;5;241m=\u001b[39m timeout \u001b[38;5;241m+\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m--> 608\u001b[0m fs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubmit(fn, \u001b[38;5;241m*\u001b[39margs) \u001b[38;5;28;01mfor\u001b[39;00m args \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39miterables)]\n\u001b[0;32m    610\u001b[0m \u001b[38;5;66;03m# Yield must be hidden in closure so that the futures are submitted\u001b[39;00m\n\u001b[0;32m    611\u001b[0m \u001b[38;5;66;03m# before the first iterator value is required.\u001b[39;00m\n\u001b[0;32m    612\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mresult_iterator\u001b[39m():\n",
      "File \u001b[1;32mc:\\Users\\yoons\\anaconda3\\Lib\\concurrent\\futures\\process.py:813\u001b[0m, in \u001b[0;36mProcessPoolExecutor.submit\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown_lock:\n\u001b[0;32m    812\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_broken:\n\u001b[1;32m--> 813\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m BrokenProcessPool(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_broken)\n\u001b[0;32m    814\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown_thread:\n\u001b[0;32m    815\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcannot schedule new futures after shutdown\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mBrokenProcessPool\u001b[0m: A child process terminated abruptly, the process pool is not usable anymore"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from ekonlpy import Mecab\n",
    "import re\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from datetime import datetime\n",
    "\n",
    "# 형태소 분석기 초기화\n",
    "mecab = Mecab()\n",
    "\n",
    "# 파일 경로\n",
    "file_path = r\"C:\\Users\\yoons\\Desktop\\금리예측프로젝트\\filter\\2010to2025_results.csv\"\n",
    "output_path = r\"C:\\Users\\yoons\\Desktop\\금리예측프로젝트\\filter\\really_data_test.csv\"\n",
    "\n",
    "# 텍스트 전처리 함수 (대괄호 및 소괄호 내 내용 삭제)\n",
    "def cleaned_(text: str):\n",
    "    pattern1 = r'\\[[^\\]]*\\]' \n",
    "    pattern2 = r'\\([^)]*\\)' \n",
    "    text = re.sub(pattern1, '', text)\n",
    "    text = re.sub(pattern2, '', text)\n",
    "    return text.strip()\n",
    "\n",
    "# 품사 태깅 및 불필요한 품사 필터링\n",
    "def process_content(content: str):\n",
    "    content = cleaned_(content)  # 텍스트 전처리\n",
    "    lemmatized = mecab.lemmatize(content)  # 품사 태깅 및 표제어 추출\n",
    "    \n",
    "    # 필요한 품사만 필터링: 명사, 동사, 형용사만\n",
    "    filtered_tags = [tag for tag in lemmatized if tag[1][0] not in ['I', 'J', 'E', 'S']]\n",
    "    return filtered_tags\n",
    "\n",
    "# 파일 읽기 및 데이터 처리\n",
    "start = datetime.now()\n",
    "\n",
    "# 데이터 로드\n",
    "korea = pd.read_csv(file_path)\n",
    "\n",
    "# 병렬 처리로 텍스트 처리\n",
    "with ProcessPoolExecutor() as executor:\n",
    "    contents_tagged = list(executor.map(process_content, korea['contents']))\n",
    "\n",
    "# 처리된 결과를 DataFrame에 추가\n",
    "korea['tagged'] = contents_tagged\n",
    "\n",
    "# 결과 파일로 저장\n",
    "korea.to_csv(output_path, encoding='utf-8-sig', index=False)\n",
    "\n",
    "end = datetime.now()\n",
    "print(f\"소요 시간: {end - start}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "청크 1 처리 완료. 저장된 행 수: 9992\n",
      "청크 2 처리 완료. 저장된 행 수: 9926\n",
      "청크 3 처리 완료. 저장된 행 수: 9961\n",
      "청크 4 처리 완료. 저장된 행 수: 10000\n",
      "청크 5 처리 완료. 저장된 행 수: 10000\n",
      "청크 6 처리 완료. 저장된 행 수: 10000\n",
      "청크 7 처리 완료. 저장된 행 수: 10000\n",
      "청크 8 처리 완료. 저장된 행 수: 4306\n",
      "전체 데이터 처리 완료! 결과가 C:\\Users\\yoons\\Desktop\\금리예측프로젝트\\filter\\real_data_test.csv에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from ekonlpy import Mecab  # Mecab으로 대체\n",
    "import re\n",
    "\n",
    "# 파일 경로\n",
    "file_path = r\"C:\\Users\\yoons\\Desktop\\금리예측프로젝트\\filter\\2010to2025_results.csv\"\n",
    "output_path = r\"C:\\Users\\yoons\\Desktop\\금리예측프로젝트\\filter\\real_data_test.csv\"\n",
    "\n",
    "# 형태소 분석기 초기화\n",
    "mecab = Mecab()\n",
    "\n",
    "# 청크 크기 설정\n",
    "chunk_size = 10000\n",
    "\n",
    "# 첫 번째 청크의 헤더를 출력할 수 있도록 처리\n",
    "for i, chunk in enumerate(pd.read_csv(file_path, chunksize=chunk_size)):\n",
    "    chunk.dropna(subset=['title', 'contents', 'date'], inplace=True)\n",
    "    chunk['contents'] = chunk['contents'].str.replace(r'[^ㄱ-ㅎ가-힣0-9A-Za-z ]', '', regex=True)\n",
    "    chunk['tagged'] = chunk['contents'].apply(lambda x: mecab.pos(x))  # pos()로 품사 태깅\n",
    "\n",
    "    # 첫 번째 청크에 헤더 저장\n",
    "    if i == 0:\n",
    "        chunk.to_csv(output_path, encoding='utf-8-sig', index=False)\n",
    "    else:\n",
    "        # 이후 청크는 헤더 없이 추가 저장\n",
    "        chunk.to_csv(output_path, encoding='utf-8-sig', index=False, mode='a', header=False)\n",
    "    \n",
    "    print(f\"청크 {i+1} 처리 완료. 저장된 행 수: {len(chunk)}\")\n",
    "\n",
    "print(f\"전체 데이터 처리 완료! 결과가 {output_path}에 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('이', 1281696), ('다', 1175029), ('는', 1022096), ('을', 869568), ('에', 741081), ('은', 693950), ('의', 650640), ('하', 560586), ('를', 549052), ('가', 537845), ('있', 452139), ('했', 445265), ('고', 421689), ('으로', 413161), ('한', 322602), ('것', 302292), ('로', 300751), ('도', 290190), ('에서', 260524), ('들', 201555), ('등', 188464), ('원', 187755), ('과', 183592), ('금리', 173755), ('년', 166135), ('할', 165616), ('월', 164073), ('일', 162055), ('만', 157587), ('인', 152409), ('수', 144019), ('적', 142781), ('기', 137835), ('억', 137241), ('와', 130885), ('다고', 130626), ('되', 128805), ('게', 124595), ('지', 123309), ('1', 118683), ('면', 118308), ('미국', 117203), ('해', 109901), ('습니다', 100797), ('보다', 99050), ('어', 95496), ('라고', 94879), ('다는', 92345), ('3', 91751), ('말', 90752), ('2', 87874), ('까지', 87275), ('상승', 85004), ('면서', 84855), ('대출', 83759), ('시장', 81805), ('경제', 81458), ('않', 79425), ('었', 78752), ('지만', 76245), ('높', 71801), ('전망', 64128), ('달러', 63780), ('인상', 63139), ('투자', 63122), ('하락', 61997), ('됐', 61055), ('될', 60760), ('경기', 60318), ('아', 59339), ('된', 59094), ('이후', 58377), ('조', 57864), ('대한', 56914), ('올해', 56597), ('기업', 56402), ('4', 56036), ('한다', 55902), ('중', 55847), ('지난', 55735), ('분기', 55557), ('5', 54081), ('예상', 53214), ('포인트', 51773), ('10', 51506), ('중국', 51383), ('던', 50816), ('받', 50423), ('수준', 48595), ('았', 48592), ('대', 48483), ('가능성', 48378), ('정부', 47916), ('더', 47465), ('없', 47322), ('다며', 47142), ('그', 46359), ('때문', 46277), ('며', 45799), ('대비', 45771)]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from collections import Counter\n",
    "\n",
    "# 저장된 CSV 파일 불러오기\n",
    "output_path = r\"C:\\Users\\yoons\\Desktop\\금리예측프로젝트\\filter\\real_data_test.csv\"\n",
    "final_df = pd.read_csv(output_path)\n",
    "\n",
    "# 'tagged' 컬럼을 리스트로 변환 (CSV 저장 시 문자열로 변환되었을 가능성 있음)\n",
    "final_df['tagged'] = final_df['tagged'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "\n",
    "# 'tokens' 컬럼 생성 (형태소 분석 결과에서 단어만 추출)\n",
    "final_df['tokens'] = final_df['tagged'].apply(lambda x: [word for word, pos in x])\n",
    "\n",
    "# 제거할 단어 리스트\n",
    "remove_words = {\"'\", \"또\", \"크\", \"N\", \"기자\", \"뉴스\", \"/\", \",\", \" \", \"G\", \"V\"}\n",
    "\n",
    "# 전체 데이터에서 토큰화된 단어 리스트를 모은 후 빈도 계산\n",
    "all_tokens = [token for sublist in final_df['tokens'] for token in sublist]\n",
    "word_counts = Counter(all_tokens)\n",
    "\n",
    "# 특정 단어 제거\n",
    "for word in remove_words:\n",
    "    if word in word_counts:\n",
    "        del word_counts[word]\n",
    "\n",
    "# 상위 100개 단어 출력\n",
    "print(word_counts.most_common(100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 불용어 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# import ast\n",
    "\n",
    "# # 문자열을 리스트로 변환\n",
    "# final_df['tokens'] = final_df['tokens'].apply(ast.literal_eval)\n",
    "\n",
    "# # 변환 확인\n",
    "# print(type(final_df['tokens'][0]))  # 이제 리스트여야 함\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'chunk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(chunk[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtagged\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mhead())  \u001b[38;5;66;03m# 상위 5개 데이터 출력\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(chunk[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtagged\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'chunk' is not defined"
     ]
    }
   ],
   "source": [
    "print(final_df['tagged'].head())  # 상위 5개 데이터 출력\n",
    "print(type(final_df['tagged'][0]))  # 첫 번째 값의 데이터 타입 확인\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtokens\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "print(df['tokens'].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('하/VV', 729816), ('되/VV', 274910), ('금리/NNG', 217961), ('있/VV', 148501), ('상승/NNG', 114106), ('보/VV', 93570), ('오르/VV', 91863), ('시장/NNG', 86730), ('대출/NNG', 86058), ('경제/NNG', 81458), ('않/VX', 79352), ('하락/NNG', 74586), ('달러/NNG', 73648), ('전망/NNG', 71990), ('높/VA', 71801), ('인상/NNG', 63139), ('투자/NNG', 63122), ('경기/NNG', 60318), ('예상/NNG', 59783), ('위하/VV', 57045), ('따르/VV', 56781), ('기업/NNG', 56402), ('중/NNG', 55847), ('fed/NNG', 55159), ('가격/NNG', 53481), ('포인트/NNG', 51773), ('받/VV', 50423), ('수준/NNG', 48595), ('가능성/NNG', 48378), ('늘/VV', 47550), ('더/MAG', 47413), ('없/VA', 47322), ('대비/NNG', 45771), ('증가/NNG', 45276), ('증시/NNG', 44700), ('물가/NNG', 44654), ('은행/NNG', 44091), ('있/VA', 43738), ('지수/NNG', 41053), ('나오/VV', 39593), ('기록/NNG', 38786), ('기대/NNG', 38754), ('금융/NNG', 38720), ('우려/NNG', 38096), ('같/VA', 38007), ('발표/NNG', 37528), ('때/NNG', 37163), ('거래/NNG', 35441), ('줄/VV', 35321), ('인하/NNG', 34574), ('분석/NNG', 34273), ('나타나/VV', 34048), ('주가/NNG', 33997), ('규모/NNG', 33692), ('영향/NNG', 33648), ('낮/VA', 33435), ('밝히/VV', 33427), ('부동산/NNG', 32328), ('설명/NNG', 31969), ('글로벌/NNG', 31966), ('가장/MAG', 31812), ('통하/VV', 31737), ('많/VA', 31440), ('자금/NNG', 31331), ('떨어/VV', 31282), ('넘/VV', 31122), ('실적/NNG', 31091), ('확대/NNG', 30815), ('인플레이션/NNG', 29829), ('기준/NNG', 29534), ('내리/VV', 29403), ('정책/NNG', 29309), ('성장/NNG', 29302), ('엔/NNG', 28990), ('상품/NNG', 28782), ('지원/NNG', 28594), ('지속/NNG', 28373), ('추가/NNG', 27857), ('점/NNG', 27472), ('필요/NNG', 26586), ('회복/NNG', 25529), ('국채/NNG', 25278), ('유지/NNG', 25086), ('외국인/NNG', 24682), ('채권/NNG', 24465), ('미/NNG', 24380), ('감소/NNG', 24096), ('주식/NNG', 24027), ('코스피/NNG', 24009), ('최대/NNG', 23699), ('부채/NNG', 23496), ('가계/NNG', 23376), ('수요/NNG', 23333), ('위험/NNG', 23195), ('부담/NNG', 23130), ('발행/NNG', 22266), ('주택/NNG', 22209), ('전/NNG', 21931), ('공급/NNG', 21898), ('수익률/NNG', 21778)]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# 제외할 품사 목록\n",
    "exclude_pos = {\"XSV\", \"VCN\", \"VCP\"}\n",
    "\n",
    "# 제외할 특정 단어 목록\n",
    "exclude_words = {\"다\", \"또\", \"크\",\"또\"}  # 여기에 제외하고 싶은 단어들을 추가하세요.\n",
    "\n",
    "# CSV 파일 불러오기\n",
    "df = pd.read_csv(\"processed_data.csv\")\n",
    "\n",
    "# 필터링하여 새로운 리스트 생성\n",
    "filtered_tokens = []\n",
    "for sublist in df['tokens']:\n",
    "    try:\n",
    "        tokens = eval(sublist)  # 문자열을 리스트로 변환 (예: \"['단어/NNG', '형용사/VA']\")\n",
    "        for token in tokens:\n",
    "            if isinstance(token, str) and '/' in token:\n",
    "                word, pos = token.rsplit('/', 1)  # '/' 기준으로 단어와 품사 분리\n",
    "                if pos not in exclude_pos and word not in exclude_words:  # 품사와 단어가 제외 목록에 없으면 추가\n",
    "                    filtered_tokens.append(token)\n",
    "    except:\n",
    "        continue  # 오류 발생 시 건너뛰기\n",
    "\n",
    "# 빈도 계산\n",
    "word_counts = Counter(filtered_tokens)\n",
    "\n",
    "# 상위 100개 출력\n",
    "print(word_counts.most_common(100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리된 데이터가 'filtered_processed_data.csv'로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 전처리된 데이터를 새로운 CSV 파일로 저장\n",
    "df.to_csv(\"filtered_real_data.csv\", index=False)\n",
    "\n",
    "# 저장된 파일 경로 출력\n",
    "print(\"전처리된 데이터가 'filtered_processed_data.csv'로 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 데이터에서 토큰화된 단어 리스트를 모은 후 빈도 계산\n",
    "#all_tokens = []\n",
    "#for sublist in final_df['tokens']:\n",
    "#    for token in sublist:\n",
    "#        if isinstance(token, tuple):  # (단어, 품사) 형태라면\n",
    "#            word, pos = token  # 튜플에서 단어와 품사를 분리\n",
    "#            if word not in [\"'\", \"N\",\"/\",\",\"]:  # 작은따옴표 및 \"N\" 제거\n",
    "#                all_tokens.append(word)  # 단어만 추가\n",
    "#        else:  # 튜플이 아닌 경우\n",
    "#            if token not in [\"'\", \"N\",\"/\",\",\"]:  # 작은따옴표 및 \"N\" 제거\n",
    "#                all_tokens.append(token)  \n",
    "\n",
    "#word_counts = Counter(all_tokens)\n",
    "\n",
    "# 상위 100개 단어 출력\n",
    "#print(word_counts.most_common(100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [('국내', 'NNG'), ('채권전문가', 'NNG'), ('100', 'SN'...\n",
      "1    [('사진', 'NNG'), ('AP', 'SL'), ('뉴욕증시', 'NNG'),...\n",
      "2    [('미국', 'NNG'), ('뉴욕', 'NNG'), ('맨해튼', 'NNP'),...\n",
      "3    [('정부', 'NNG'), ('는', 'JX'), ('소상공인', 'NNG'), ...\n",
      "4    [('사진', 'NNG'), ('게티', 'NNP'), ('이미지', 'NNP'),...\n",
      "Name: tagged, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 파일 불러오기\n",
    "df = pd.read_csv(\"real_data_test.csv\")\n",
    "\n",
    "# 'tagged' 컬럼의 샘플 데이터 출력\n",
    "print(df['tagged'].head())  # 첫 5개의 샘플을 확인\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [('국내', 'NNG'), ('채권전문가', 'NNG'), ('100', 'SN'...\n",
      "1    [('사진', 'NNG'), ('AP', 'SL'), ('뉴욕증시', 'NNG'),...\n",
      "2    [('미국', 'NNG'), ('뉴욕', 'NNG'), ('맨해튼', 'NNP'),...\n",
      "3    [('정부', 'NNG'), ('는', 'JX'), ('소상공인', 'NNG'), ...\n",
      "4    [('사진', 'NNG'), ('게티', 'NNP'), ('이미지', 'NNP'),...\n",
      "Name: tagged, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 저장된 CSV 파일 불러오기\n",
    "output_path = r\"C:\\Users\\yoons\\Desktop\\금리예측프로젝트\\filter\\real_data_test.csv\"\n",
    "final_df = pd.read_csv(output_path)\n",
    "\n",
    "# 'tagged' 컬럼의 첫 5개 값을 확인\n",
    "print(final_df['tagged'].head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
