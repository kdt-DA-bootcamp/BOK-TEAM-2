{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdafD2d1Zans",
        "outputId": "05ea65d4-1746-4b0c-ee86-b8979a69e056"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ekonlpy\n",
            "  Downloading ekonlpy-2.0.6-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.6 in /usr/local/lib/python3.11/dist-packages (from ekonlpy) (8.1.8)\n",
            "Collecting fugashi<2.0.0,>=1.3.3 (from ekonlpy)\n",
            "  Downloading fugashi-1.4.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Collecting mecab-ko-dic<2.0.0,>=1.0.0 (from ekonlpy)\n",
            "  Downloading mecab-ko-dic-1.0.0.tar.gz (33.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.2/33.2 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.11/dist-packages (from ekonlpy) (3.9.1)\n",
            "Requirement already satisfied: pandas<=2.2.3,>=1.5.3 in /usr/local/lib/python3.11/dist-packages (from ekonlpy) (2.2.2)\n",
            "Requirement already satisfied: scipy<=1.13.1,>1.10.0 in /usr/local/lib/python3.11/dist-packages (from ekonlpy) (1.13.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk<4.0.0,>=3.8.1->ekonlpy) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk<4.0.0,>=3.8.1->ekonlpy) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk<4.0.0,>=3.8.1->ekonlpy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas<=2.2.3,>=1.5.3->ekonlpy) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<=2.2.3,>=1.5.3->ekonlpy) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<=2.2.3,>=1.5.3->ekonlpy) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<=2.2.3,>=1.5.3->ekonlpy) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<=2.2.3,>=1.5.3->ekonlpy) (1.17.0)\n",
            "Downloading ekonlpy-2.0.6-py3-none-any.whl (10.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.3/10.3 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fugashi-1.4.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (698 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m698.0/698.0 kB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: mecab-ko-dic\n",
            "  Building wheel for mecab-ko-dic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mecab-ko-dic: filename=mecab_ko_dic-1.0.0-py3-none-any.whl size=33424393 sha256=ae6feeb8ec72ff40151f6ba599ebfc091c1afff8c01dcaea050b22924139b611\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/9d/25/2fd8c3b4ee5d7ed5b676121162e880a941864282d051cdf7a1\n",
            "Successfully built mecab-ko-dic\n",
            "Installing collected packages: mecab-ko-dic, fugashi, ekonlpy\n",
            "Successfully installed ekonlpy-2.0.6 fugashi-1.4.0 mecab-ko-dic-1.0.0\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "E: Unable to locate package mecab-ko-dic\n"
          ]
        }
      ],
      "source": [
        "# ekonlpy 설치\n",
        "!pip install ekonlpy\n",
        "\n",
        "# mecab-ko-dic 설치 (필요한 경우)\n",
        "!apt-get install mecab-ko-dic"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from ekonlpy import Mecab # 경제 분야 특화 토크나이저\n",
        "\n",
        "mecab = Mecab()\n",
        "\n",
        "# ALLOWED_TAGS에 포함된 품사만 필터링\n",
        "ALLOWED_TAGS = {'NNG', 'VA', 'VAX', 'MAG', 'negations'}\n",
        "\n",
        "# CSV 파일 로드\n",
        "df = pd.read_csv(\"/content/conferences_sentences.csv\")\n",
        "\n",
        "# 문자열 형태의 리스트를 실제 리스트로 변환\n",
        "df[\"sentences\"] = df[\"sentences\"].apply(eval)  # 리스트 형태 변환\n",
        "\n",
        "# 문장 단위로 데이터 풀기 (explode 사용)\n",
        "df = df.explode(\"sentences\").reset_index(drop=True)\n",
        "\n",
        "# 날짜(date)를 기준으로 document_id 생성\n",
        "df[\"document_id\"] = df[\"date\"].factorize()[0] + 1\n",
        "\n",
        "# 각 document_id 내에서 문장 순서대로 sentence_id 추가\n",
        "df[\"sentence_id\"] = df.groupby(\"document_id\").cumcount() + 1\n",
        "\n",
        "# ekonply를 이용한 토큰화\n",
        "def lemmatize_sentence(sentence):\n",
        "    # 전체 형태소 분석\n",
        "    all_tokens = [m[0] for m in mecab.pos(sentence)]\n",
        "\n",
        "    # ALLOWED_TAGS에 해당하는 품사만 필터링\n",
        "    filtered_tokens = [m[0] for m in mecab.pos(sentence) if m[1] in ALLOWED_TAGS]\n",
        "\n",
        "    return \" \".join(all_tokens), \" \".join(filtered_tokens)\n",
        "\n",
        "# 새로운 컬럼에 토큰화된 문장 및 필터링된 문장 추가\n",
        "df[[\"tokenized_sentence\", \"filtered_tokenized_sentence\"]] = df[\"sentences\"].apply(lambda x: pd.Series(lemmatize_sentence(x)))\n",
        "\n",
        "# 컬럼 정리 및 저장\n",
        "df = df[[\"date\", \"document_id\", \"sentence_id\", \"tokenized_sentence\", \"filtered_tokenized_sentence\"]]\n",
        "print(df.head(20))\n",
        "\n",
        "df.to_csv(\"press_conference_sentences.csv\", index=False)\n",
        "\n",
        "print(\"기자회견 문서 데이터 변환 및 토큰화 완료!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YhFnQjhaN8L",
        "outputId": "cdef6cd5-2b42-4f07-d9b9-d4cf165c8fc3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          date  document_id  sentence_id  \\\n",
            "0   2009-04-09            1            1   \n",
            "1   2009-04-09            1            2   \n",
            "2   2009-04-09            1            3   \n",
            "3   2009-04-09            1            4   \n",
            "4   2009-04-09            1            5   \n",
            "5   2009-04-09            1            6   \n",
            "6   2009-05-12            2            1   \n",
            "7   2009-05-12            2            2   \n",
            "8   2009-05-12            2            3   \n",
            "9   2009-05-12            2            4   \n",
            "10  2009-05-12            2            5   \n",
            "11  2009-05-12            2            6   \n",
            "12  2009-06-11            3            1   \n",
            "13  2009-06-11            3            2   \n",
            "14  2009-06-11            3            3   \n",
            "15  2009-06-11            3            4   \n",
            "16  2009-06-11            3            5   \n",
            "17  2009-06-11            3            6   \n",
            "18  2009-07-09            4            1   \n",
            "19  2009-07-09            4            2   \n",
            "\n",
            "                                   tokenized_sentence  \\\n",
            "0   금융통화위원회 는 다음 통화정책 방향 결정시 까지 한국은행 기준금리 를 현 수준 (...   \n",
            "1   최근 국내 경기 는 내수 와 수출 모두 감소세 를 지속 하 면서 계속 위축 되 고 ...   \n",
            "2   소비자 물가 는 국제 유가 가 안정세 를 보이 는 가운데 경기 부진 에 따른 수요 ...   \n",
            "3            부동산시장 에서 는 거래 위축 및 가격 하락 현상 이 지속 되 고 있 음   \n",
            "4   금융시장 에서 는 환율 , 주가 등가격 변수 가 개선 된 모습 을 나타내 었 으며 ...   \n",
            "5   앞 으로 통화정책 은 당분간 금융 완화 기조 를 유지 하 면서 경기 의 과도 한 위...   \n",
            "6   금융통화위원회 는 다음 통화정책 방향 결정시 까지 한국은행 기준금리 를 현 수준 (...   \n",
            "7   최근 국내 경기 는 내수 부진 에 도 불구 하 고 수출 감소세 둔화 와 적극적 인 ...   \n",
            "8   소비자 물가 는 국제 유가 의 안정 , 경기 부진 에 따른 수요 압력 완화 등 으로...   \n",
            "9   부동산시장 에서 는 수도권 일부 에서 거래량 이 늘어나 면서 가격 이 반등 하 는 ...   \n",
            "10  금융시장 에서 는 환율 , 주가 등가격 변수 가 개선 추세 를 지속 하 는 가운데 ...   \n",
            "11  앞 으로 통화정책 은 당분간 금융 완화 기조 를 유지 하 면서 경기 회복 을 뒷받침...   \n",
            "12  금융통화위원회 는 다음 통화정책 방향 결정시 까지 한국은행 기준금리 를 현 수준 (...   \n",
            "13  최근 국내 경기 는 적극적 인 재정 통화정책 등 에 힘입 어 내수 부진 이 완화 되...   \n",
            "14  소비자 물가 는 경기 부진 에 따른 수요 압력 완화 , 환율 의 하향 안정 등 으로...   \n",
            "15                       부동산 가격 은 소폭 의 상승세 가 지속 되 었 음   \n",
            "16  금융시장 에서 는 환율 , 주가 등가격 변수 가 안정 적 인 움직임 을 보이 는 가...   \n",
            "17  앞 으로 통화정책 은 당분간 금융 완화 기조 를 유지 하 면서 최근 의 경기 및 금...   \n",
            "18  금융통화위원회 는 다음 통화정책 방향 결정시 까지 한국은행 기준금리 를 현 수준 (...   \n",
            "19  최근 국내 경기 는 적극적 인 재정 통화정책 등 에 힘입 어 내수 및 수출 부진 이...   \n",
            "\n",
            "                          filtered_tokenized_sentence  \n",
            "0      금융통화위원회 다음 통화정책 방향 결정시 한국은행 기준금리 수준 유지 통화정책 운용  \n",
            "1   최근 국내 경기 내수 수출 모두 감소세 지속 계속 위축 하강 속도 다소 완만 해지 ...  \n",
            "2   소비자 물가 국제 유가 안정세 가운데 경기 부진 수요 압력 완화 오름세 둔화 앞 이...  \n",
            "3                             부동산시장 거래 위축 가격 하락 현상 지속  \n",
            "4   금융시장 환율 주가 등가격 변수 개선 모습 금융기관 대출태도 완화 가계 중소기업 대...  \n",
            "5   앞 통화정책 당분간 금융 완화 기조 유지 경기 과도 위축 방지 금융시장 안정 도모 ...  \n",
            "6      금융통화위원회 다음 통화정책 방향 결정시 한국은행 기준금리 수준 유지 통화정책 운용  \n",
            "7   최근 국내 경기 내수 부진 불구 수출 감소세 둔화 적극적 재정 통화정책 하강 속도 ...  \n",
            "8       소비자 물가 국제 유가 안정 경기 부진 수요 압력 완화 오름세 둔화 앞 이러 추세  \n",
            "9                          부동산시장 수도권 일부 거래량 가격 반등 움직임  \n",
            "10  금융시장 환율 주가 등가격 변수 개선 추세 지속 가운데 가계 중소기업 대출 꾸준히 ...  \n",
            "11  앞 통화정책 당분간 금융 완화 기조 유지 경기 회복 뒷받침 금융시장 안정 도모 주안...  \n",
            "12     금융통화위원회 다음 통화정책 방향 결정시 한국은행 기준금리 수준 유지 통화정책 운용  \n",
            "13  최근 국내 경기 적극적 재정 통화정책 내수 부진 완화 생산 활동 호전 하강 모습 국...  \n",
            "14              소비자 물가 경기 부진 수요 압력 완화 환율 하향 안정 오름세 둔화  \n",
            "15                                   부동산 가격 소폭 상승세 지속  \n",
            "16  금융시장 환율 주가 등가격 변수 안정 움직임 가운데 가계 중소기업 대출 꾸준히 신용...  \n",
            "17  앞 통화정책 당분간 금융 완화 기조 유지 최근 경기 금융시장 개선 움직임 지속 주안...  \n",
            "18     금융통화위원회 다음 통화정책 방향 결정시 한국은행 기준금리 수준 유지 통화정책 운용  \n",
            "19  최근 국내 경기 적극적 재정 통화정책 내수 수출 부진 완화 그간 강세 모습 국제 원...  \n",
            "기자회견 문서 데이터 변환 및 토큰화 완료!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j-qVbty0aTLc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}