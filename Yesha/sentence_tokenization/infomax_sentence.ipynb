{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 인포맥스 문장 토큰화 및 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from kiwipiepy import Kiwi\n",
    "kiwi = Kiwi()\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파일크기: 490.12 MB\n",
      "C:/Users/iq750/bootcamp_git/대용량 파일 관리/infomax_split/infomax_split_1.csv 저장 완료\n",
      "C:/Users/iq750/bootcamp_git/대용량 파일 관리/infomax_split/infomax_split_2.csv 저장 완료\n",
      "C:/Users/iq750/bootcamp_git/대용량 파일 관리/infomax_split/infomax_split_3.csv 저장 완료\n",
      "C:/Users/iq750/bootcamp_git/대용량 파일 관리/infomax_split/infomax_split_4.csv 저장 완료\n",
      "C:/Users/iq750/bootcamp_git/대용량 파일 관리/infomax_split/infomax_split_5.csv 저장 완료\n",
      "C:/Users/iq750/bootcamp_git/대용량 파일 관리/infomax_split/infomax_split_6.csv 저장 완료\n",
      "C:/Users/iq750/bootcamp_git/대용량 파일 관리/infomax_split/infomax_split_7.csv 저장 완료\n"
     ]
    }
   ],
   "source": [
    "file_path = \"C:/Users/iq750/bootcamp_git/대용량 파일 관리/infomax_processed.csv\"\n",
    "\n",
    "file_size = os.path.getsize(file_path)\n",
    "print(f\"파일크기: {file_size / (1024*1024):.2f} MB\")\n",
    "# 디렉터리 생성\n",
    "output_dir = \"C:/Users/iq750/bootcamp_git/대용량 파일 관리/infomax_split\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    " # 여기서부터 잘못되어있음 뭐가 뭔지 모르겠지만\n",
    "\n",
    "# 파일을 일정 크기로 나누어 저장\n",
    "chunksize = 12000\n",
    "for i, chunk in enumerate(pd.read_csv(file_path, chunksize=chunksize)):\n",
    "    output_file = f'{output_dir}/infomax_split_{i+1}.csv'\n",
    "    chunk.to_csv(output_file, index = False, encoding='utf-8')\n",
    "    print(f\"{output_file} 저장 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['서울외환시장의 외환딜러들은 16일 달러-원 환율이 1,110원대에서 방향성을 탐색할 것으로 전망했다.', '이날 삼성전자가 배당금을 지급하는 가운데 관련 역송금 물량이 나올 경우 환율에 상방 압력을 가할 것으로 보인다.', '아직 배당금 관련 물량이 시장에 적극적으로 나오지는 않은 것으로 추정되지만, 배당금 지급 당일인 만큼 역송금 수요가 두드러질 수 있다.', '다만, 시장 예상보다 역송금 수요가 나오지 않을 수도 있다.', '한편 대외 재료는 환율의 하락을 지지하고 있다.', '미국의 10년물 국채 금리는 한 달 만에 1.6% 아래로 하락했다.', '또 미국의 경제 지표가 호조를 나타내면서 위험 선호 심리는 이어졌다.', '해외브로커들은 역외차액결제선물환(NDF) 시장에서 지난밤 달러-원 1개월물이 1,116.90원에 최종 호가가 나왔다고 전했다.', '최근 1개월물 스와프포인트(0.15원)를 고려하면 전일 서울외환시장 현물환 종가(1,117.60원) 대비 0.85원 내린 셈이다.', '이날 달러-원 환율 예상 레인지는 1,112.00∼1,122.00원으로 전망됐다. ◇', 'A은행 딜러 미국 경기 반등에도 연방준비제도의 완화적 기조로 달러화는 하락 압력을 받을 것으로 보인다.', '다만, 이날 삼성전자의 배당금 지급이 예정된 만큼 환율은 상승 흐름을 보일 가능성이 있다.', '예상 레인지: 1,114.00~1,122.00원 ◇ B은행 딜러 이날 달러-원 환율은 1,110원대 중후반에서 상하단이 막힌 흐름 나타낼 것으로 본다.', '삼성전자 배당금 지급 당일이지만, 투자 심리가 상당 부분 회복된 상황이라 물량이 나올지는 미지수다.', '위험 선호 심리 등 다른 재료는 하방 쪽으로 본다.', '이날 환율은 1,110원 아래도 어렵고, 1,120원 위도 어려운 상황 같다.', '예상 레인지: 1,112.00~1,120.00원 ◇ C은행 딜러 간밤 미국 국채 금리가 큰 폭 하락했으나 달러 약세 모습은 그다지 나타나지 않았다.', '이날 삼전 배당금 지급일인 가운데 수급 얼마나 출회할지 주목된다.', '최근 레벨이 상승하면 역외 및 네고의 달러 매도 물량이 적극적으로 출회 중이라 이날도 역외 및 네고 물량 출회 레벨이 중요해 보인다.', '예상 레인지: 1,114.00~1,122.00원 hrlim']\n",
      "[]\n",
      "['전일 한국은행 금융통화위원회 결과가 다소 매파적(통화긴축 선호)이었다고 평가된 가운데 국고채 중장기물 금리가 상방 압력을 받았다.', '채권시장 참가자들은 향후 단기물과 초장기물을 보유하는 바벨전략이 유효할지에 주목했다.', '16일 연합인포맥스 최종호가 수익률 추이(화면번호 4512)에 따르면 전일 국고채 3년물 지표금리는 4.5bp 상승한 1.147%로 마감했다.', '국고채 5년물은 4.6bp 오른 1.570%로, 10년물은 3.0bp 높아진 2.020%로 장을 마쳤다.', '전일 열린 한은 금통위 회의가 다소 매파적이었던 영향을 받았다고 풀이된다.', '통화정책방향 결정문과 한은 총재의 발언에서 경제 회복 전망은 강화했다.', '국고채 중장기물이 약세를 보인 반면 초장기 구간은 소폭 강세를 나타내면서 수익률 커브는 평탄화 압력을 받았다.', '국고채 30년물 금리는 하루 전보다 0.1bp 하락한 2.092%로, 20년물 금리는 0.2bp 내린 2.102%로 고시됐다.', '특히 이날 실시되는 국고채 50년물 입찰과 다음 거래일(19일) 10년물 입찰 등을 대기하고 있었던 만큼 초장기물 강세는 이례적으로 받아들여졌다.', '전일 장중 금통위 회의가 끝난 뒤 국고채 30년물 금리는 민간평가사 금리 대비 1.3bp까지 낙폭을 확대하기도 했다.', '채권시장 참가자들은 만기 1년 이내 단기물과 만기 30년 부근 초장기물 등을 매수하는 전략을 사용해볼 만하다고 진단했다.', '한은 총재의 발언에서도 확인되듯 경제성장률 전망치 상향에도 잠재성장률이 신종 코로나바이러스 감염증(코로나19) 여파로 떨어진 점을 초장기물 강세 배경으로 꼽았다.', '분기 초 장기투자기관의 자금 집행이 재개된 가운데 지난주부터 보험사를 중심으로 채권 듀레이션을 늘린다는 소식도 전해졌다.', '초장기물 매수 요인이다.', '최근 장기투자기관의 포지션 손절과 숏(매도) 재료들이 대부분 노출됐다는 점도 심리적으로 초장기 금리 상단을 제한할 것으로 관측된다.', 'A 보험사의 한 채권 딜러는 \"지난달 장기투자 기관들이 스티프너를 잡았다가 손절을 많이 했었는데 겁나서 다시 스티프너로 들어가지 못하는 측면도 있다\"고 설명했다.', 'B 증권사의 한 채권 딜러는 \"당장 추가적인 이슈가 없다면 소강상태로 들어갈 것\"이라며 \"롱(매수) 재료가 있다기보다 숏 재료가 없어 일단락되는 차원에서 초장기 금리가 빠질 수 있다. 50년 입찰 수요도 견조할 것 같다\"고 전망했다.', '긴 호흡에서 당국의 매파적 스탠스는 정책금리 인상에 대한 우려를 키우면서 중장기 구간에 부담을 주지만 1년 부근 단기물은 영향이 상대적으로 덜할 것이라고 평가된다.', 'C 시중은행 딜러는 \"금리 인상을 프라이싱 하면 2~3년 구간의 타격이 제일 큰 반면 1년 언저리 단기는 금리 민감도가 낮아 큰 영향은 없을 것\"이라고 내다봤다.', 'D 시중은행의 한 채권 딜러는 \"1년은 금리 변동 리스크에 다소 부담이 적은 구간이어서 캐리 측면으로 접근하면 3~5년 구간보다는 수요가 견조한 상황\"이라고 분석했다.', 'mjlee']\n",
      "['경기회복 기대로 미국 국채금리 상승세가 지속하면서 지난달 연기금투자풀의 채권형 펀드가 부진한 성과를 올렸다.', '특히 해외채권형 운용수익률은 마이너스(-) 10%에 머물렀다.', '16일 기획재정부와 금융투자업계에 따르면 올해 초부터 지난달까지 연기금투자풀 국내채권형의 연환산 운용수익률은 0.31%로 집계됐다.', '3월 수익률만 보면 -1.84%로 2개월 연속 마이너스였다.', '벤치마크와 비교해서도 0.43%포인트(P) 낮았다.', '다만, 국내채권형의 연초 이후 수익률은 벤치마크를 0.03%P 웃돌았다.', '연기금투자풀 관계자는 \"3월 국내 채권시장은 대외금리 상승과 시장 변동성 확대에 따른 국내 기관들의 손절성 매도로 인해 국고채 금리 전 구간이 상승하는 약세장이었다\"고 설명했다.', '미국 국채금리 상승 여파가 이어지면서 해외채권형의 연초 이후 연환산 수익률은 -10.03%를 기록했다.', '벤치마크와 비교해도 0.70%P 낮은 성과였다.', '3월 수익률은 벤치마크보다 1.12%P 낮은 -3.87%였다.', '이례적으로 수익률이 급락했던 전월(-23.74%)에 비해서는 다소 진정되는 모습을 보였다.', '해외채권형의 주간운용사별 수익률도 크게 엇갈렸다.', '삼성자산운용의 해외채권형 연초 이후 수익률은 -9.76%로 벤치마크를 0.53%P 하회했다.', '한국투자신탁운용은 벤치마크보다 2.67%P 낮은 -13.05%의 수익률을 올렸다.', '연초부터 지난달까지 국내주식형 수익률은 7.61%로 벤치마크를 1.04%P 웃돌았다.', '해외주식형은 8.82%로 벤치마크보다 1.07%P 높았다.', '주식·채권 혼합형의 연초 이후 수익률은 1.95%였다.', '벤치마크보다 0.39%P 높은 성과다.', '주간운용사별로 보면 삼성운용 수익률은 국내주식형 7.62%, 해외주식형 8.63%, 혼합형 2.12%였다.', '한국운용은 국내주식형 7.60%, 해외주식형 8.97%, 혼합형 1.44%를 기록했다.', '머니마켓펀드(MMF)의 연초 이후 수익률은 0.71%로 0.08%P 높았다.', '국내대체형과 주가연계펀드(ELF) 수익률은 각각 0.46%와 -0.75%였다.', '연기금투자풀의 지난달 말 기준 운용규모(기간말잔)는 전월보다 2조780억원 줄어든 29조8천539억원이다.', '삼성운용이 22조3천478억원, 한국운용이 7조5천61억원을 나눠 운용한다.', '자산유형별로는 국내채권 12조7천717억원(42.8%), MMF 8조1천679억원(27.4%), 혼합형 7조6천88억원(25.5%), 해외주식 5천109억원(1.7%), 해외채권 3천701억원(1.2%), 국내주식 3천487억원(1.2%), 국내대체 500억원(0.2%), ELF 259억원(0.1%) 순으로 비중이 높았다.', 'wchoi']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m cnt \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m content \u001b[38;5;129;01min\u001b[39;00m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m----> 5\u001b[0m     sents \u001b[38;5;241m=\u001b[39m [s\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m  \u001b[43mkiwi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit_into_sents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[0;32m      6\u001b[0m     cnt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cnt \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m146\u001b[39m, \u001b[38;5;241m147\u001b[39m, \u001b[38;5;241m148\u001b[39m, \u001b[38;5;241m149\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\iq750\\anaconda3\\envs\\nlp\\lib\\site-packages\\kiwipiepy\\_wrap.py:1574\u001b[0m, in \u001b[0;36mKiwi.split_into_sents\u001b[1;34m(self, text, match_options, normalize_coda, z_coda, split_complex, compatible_jamo, saisiot, stopwords, blocklist, return_tokens, return_sub_sents)\u001b[0m\n\u001b[0;32m   1571\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\n\u001b[0;32m   1573\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(text, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m-> 1574\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _make_result((\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m   1575\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mmatch_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmatch_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m   1576\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mnormalize_coda\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnormalize_coda\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m   1577\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mz_coda\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mz_coda\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m   1578\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43msplit_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_complex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m   1579\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mcompatible_jamo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompatible_jamo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1580\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43msaisiot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msaisiot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1581\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mblocklist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblocklist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m   1582\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43msplit_sents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m, text))\n\u001b[0;32m   1584\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmap\u001b[39m(_make_result, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tokenize(text, \n\u001b[0;32m   1585\u001b[0m                                         match_options\u001b[38;5;241m=\u001b[39mmatch_options, \n\u001b[0;32m   1586\u001b[0m                                         normalize_coda\u001b[38;5;241m=\u001b[39mnormalize_coda, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1592\u001b[0m                                         split_sents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[0;32m   1593\u001b[0m                                         echo\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n",
      "File \u001b[1;32mc:\\Users\\iq750\\anaconda3\\envs\\nlp\\lib\\site-packages\\kiwipiepy\\_wrap.py:1215\u001b[0m, in \u001b[0;36mKiwi._tokenize\u001b[1;34m(self, text, match_options, normalize_coda, z_coda, split_complex, compatible_jamo, saisiot, split_sents, stopwords, echo, blocklist, pretokenized)\u001b[0m\n\u001b[0;32m   1213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(text, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   1214\u001b[0m     echo \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 1215\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_refine_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43manalyze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatch_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblocklist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretokenized\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1217\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmap\u001b[39m(_refine_result_with_echo \u001b[38;5;28;01mif\u001b[39;00m echo \u001b[38;5;28;01melse\u001b[39;00m _refine_result, \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39manalyze(text, \u001b[38;5;241m1\u001b[39m, match_options, echo, blocklist, pretokenized))\n",
      "File \u001b[1;32mc:\\Users\\iq750\\anaconda3\\envs\\nlp\\lib\\site-packages\\kiwipiepy\\_wrap.py:1173\u001b[0m, in \u001b[0;36mKiwi._tokenize.<locals>._refine_result\u001b[1;34m(results)\u001b[0m\n\u001b[0;32m   1159\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_tokenize\u001b[39m(\u001b[38;5;28mself\u001b[39m, \n\u001b[0;32m   1160\u001b[0m     text:Union[\u001b[38;5;28mstr\u001b[39m, Iterable[\u001b[38;5;28mstr\u001b[39m]], \n\u001b[0;32m   1161\u001b[0m     match_options:\u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m Match\u001b[38;5;241m.\u001b[39mALL,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1171\u001b[0m     pretokenized:Optional[Union[Callable[[\u001b[38;5;28mstr\u001b[39m], PretokenizedTokenList], PretokenizedTokenList]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1172\u001b[0m ):\n\u001b[1;32m-> 1173\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_refine_result\u001b[39m(results):\n\u001b[0;32m   1174\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m split_sents:\n\u001b[0;32m   1175\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m results[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m stopwords \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m stopwords\u001b[38;5;241m.\u001b[39mfilter(results[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('C:/Users/iq750/bootcamp_git/대용량 파일 관리/infomax_split/infomax_split_5.csv')\n",
    "df.fillna(\"\", inplace=True)\n",
    "cnt = 0\n",
    "for content in df['content']:\n",
    "    sents = [s.text for s in  kiwi.split_into_sents(content)]\n",
    "    cnt += 1\n",
    "    if cnt in [146, 147, 148, 149]:\n",
    "        print(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(content):\n",
    "    pattern = r'\\([^)]*\\)' \n",
    "    content = re.sub(pattern, '', content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0번째: 😂\n",
      "파일 불러오기 완료\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m infomax \u001b[38;5;241m=\u001b[39m infomax\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, inplace \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m파일 불러오기 완료\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m content \u001b[38;5;129;01min\u001b[39;00m \u001b[43minfomax\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m:\n\u001b[0;32m     11\u001b[0m     sentences \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(content) :\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# 전처리 끝난 파일을 사용하여 분리가 나쁘지 않게 되는 편\n",
    "csv_files = sorted([f for f in os.listdir(output_dir) if f.endswith(\".csv\")])\n",
    "for i in range(len(csv_files)):\n",
    "    print(f\"{i}번째: 😂\")\n",
    "    # 파일 불러오기\n",
    "    file_path = f'C:/Users/iq750/bootcamp_git/대용량 파일 관리/infomax_split/infomax_split_{i+1}.csv'\n",
    "    infomax = pd.read_csv(file_path)\n",
    "    infomax = infomax.fillna(\"\", inplace = True)\n",
    "    print(\"파일 불러오기 완료\")\n",
    "    for content in infomax['content']:\n",
    "        sentences = []\n",
    "        if len(content) :\n",
    "            sents = [s.text for s in kiwi.split_into_sents(clean(content))]\n",
    "            sentences.append(sents)\n",
    "        else :\n",
    "            sents = []\n",
    "        print(sentences)\n",
    "        sentences.append(sents)\n",
    "    print(\"문장 분리 완료\")\n",
    "\n",
    "    infomax['sentences'] = sentences\n",
    "\n",
    "    output_file = f'{output_dir}/infomax_sentences_{i+1}.csv'\n",
    "    infomax[['date','sentences']].to_csv(output_file, encoding='utf-8', index=False)\n",
    "    print(\"자료 저장 완료\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0번째: 😂\n",
      "파일 불러오기 완료\n",
      "문장 분리 완료\n",
      "자료 저장 완료\n",
      "1번째: 😂\n",
      "파일 불러오기 완료\n",
      "문장 분리 완료\n",
      "자료 저장 완료\n",
      "2번째: 😂\n",
      "파일 불러오기 완료\n",
      "문장 분리 완료\n",
      "자료 저장 완료\n",
      "3번째: 😂\n",
      "파일 불러오기 완료\n",
      "문장 분리 완료\n",
      "자료 저장 완료\n",
      "4번째: 😂\n",
      "파일 불러오기 완료\n",
      "문장 분리 완료\n",
      "자료 저장 완료\n",
      "5번째: 😂\n",
      "파일 불러오기 완료\n",
      "문장 분리 완료\n",
      "자료 저장 완료\n",
      "6번째: 😂\n",
      "파일 불러오기 완료\n",
      "문장 분리 완료\n",
      "자료 저장 완료\n"
     ]
    }
   ],
   "source": [
    "csv_files = sorted([f for f in os.listdir(output_dir) if f.endswith(\".csv\")])\n",
    "for i in range(len(csv_files)):\n",
    "    print(f\"{i}번째: 😂\")\n",
    "    \n",
    "    # 파일 불러오기\n",
    "    file_path = f'C:/Users/iq750/bootcamp_git/대용량 파일 관리/infomax_split/infomax_split_{i+1}.csv'\n",
    "    infomax = pd.read_csv(file_path)\n",
    "    \n",
    "    # 결측치 처리\n",
    "    infomax.fillna(\"\", inplace=True)\n",
    "    print(\"파일 불러오기 완료\")\n",
    "    \n",
    "    sentences = []  # sentences 리스트를 반복문 밖에서 초기화 (중복 방지)\n",
    "    \n",
    "    for content in infomax['content']:\n",
    "        # content가 None일 경우 빈 문자열로 대체\n",
    "        if content is None:\n",
    "            content = \"\"\n",
    "        \n",
    "        if len(content):\n",
    "            cleaned_content = clean(content)  # content를 clean 함수로 처리\n",
    "            # clean된 내용이 None일 경우 빈 문자열로 대체\n",
    "            if cleaned_content is None:\n",
    "                cleaned_content = \"\"\n",
    "            sents = [s.text for s in kiwi.split_into_sents(cleaned_content)]\n",
    "            sentences.append(sents)\n",
    "        else:\n",
    "            sentences.append([])  # 빈 리스트 추가\n",
    "    \n",
    "    print(\"문장 분리 완료\")\n",
    "    \n",
    "    # sentences 리스트를 데이터프레임에 추가\n",
    "    infomax['sentences'] = sentences\n",
    "\n",
    "    # 결과 저장\n",
    "    output_file = f'{output_dir}/infomax_sentences_{i+1}.csv'\n",
    "    infomax[['date', 'sentences']].to_csv(output_file, encoding='utf-8', index=False)\n",
    "    print(\"자료 저장 완료\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
