{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "공통 단어 개수: 5086\n",
      "hawkish 전체 단어 개수: 10000\n",
      "dovish 전체 단어 개수: 10000\n",
      "필터링 후 hawkish 단어 개수: 4914\n",
      "필터링 후 dovish 단어 개수: 4914\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "word_dic = pd.read_csv('word_dictionary.csv', dtype=str)\n",
    "\n",
    "# 1. 분리\n",
    "df_hawkish = pd.DataFrame(word_dic['hawkish'], dtype=str)\n",
    "df_dovish = pd.DataFrame(word_dic['dovish'], dtype=str)\n",
    "\n",
    "# 2-1. 내부 중복 제거\n",
    "df_hawkish = df_hawkish.drop_duplicates()\n",
    "df_dovish = df_dovish.drop_duplicates()\n",
    "\n",
    "# 2-2. 공통 단어 추출\n",
    "common_values = set(df_hawkish['hawkish']).intersection(set(df_dovish['dovish']))\n",
    "print(\"공통 단어 개수:\", len(common_values))\n",
    "\n",
    "# 각 컬럼의 전체 단어 개수 확인\n",
    "print(\"hawkish 전체 단어 개수:\", df_hawkish['hawkish'].nunique())\n",
    "print(\"dovish 전체 단어 개수:\", df_dovish['dovish'].nunique())\n",
    "\n",
    "# 교집합에 해당하는 값 삭제\n",
    "df_hawkish = df_hawkish[~df_hawkish['hawkish'].isin(common_values)]\n",
    "df_dovish = df_dovish[~df_dovish['dovish'].isin(common_values)]\n",
    "\n",
    "# 인덱스 재설정 및 결측치 제거\n",
    "df_hawkish = df_hawkish.reset_index(drop=True)\n",
    "df_dovish = df_dovish.reset_index(drop=True)\n",
    "df_hawkish.dropna(inplace=True)\n",
    "df_dovish.dropna(inplace=True)\n",
    "\n",
    "print(\"필터링 후 hawkish 단어 개수:\", df_hawkish.shape[0])\n",
    "print(\"필터링 후 dovish 단어 개수:\", df_dovish.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dovish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>메르스</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>국민투표</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>실효</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>점_고려</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>메르스사태</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dovish\n",
       "0    메르스\n",
       "1   국민투표\n",
       "2     실효\n",
       "3   점_고려\n",
       "4  메르스사태"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dovish.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hawkish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>빅_스텝</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>오미크론</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>인상_기조</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>임금_상승</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>지역_은행</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  hawkish\n",
       "0    빅_스텝\n",
       "1    오미크론\n",
       "2   인상_기조\n",
       "3   임금_상승\n",
       "4   지역_은행"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hawkish.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.concat([df_hawkish, df_dovish], axis=1)\n",
    "result_df.to_csv('word_dictionary_final.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('word_dictionary_final.csv', dtype=str)\n",
    "\n",
    "def simplify_word(word):\n",
    "\n",
    "    if pd.isna(word):\n",
    "        return word\n",
    "    \n",
    "    # 밑줄('_') 기준으로 분리\n",
    "    parts = word.split('_')\n",
    "    \n",
    "    # 첫 번째 요소를 시작으로 연속 중복 제거\n",
    "    new_parts = [parts[0]]\n",
    "    for part in parts[1:]:\n",
    "        if part != new_parts[-1]:\n",
    "            new_parts.append(part)\n",
    "    \n",
    "    # 리스트를 띄어쓰기로 연결하여 반환\n",
    "    return ' '.join(new_parts)\n",
    "\n",
    "for col in df.columns:\n",
    "    df[col] = df[col].apply(simplify_word)\n",
    "\n",
    "# 결과를 새로운 CSV 파일로 저장 (UTF-8 with BOM: 엑셀 등에서 한글 깨짐 방지)\n",
    "df.to_csv('word_dictionary_cleaned.csv', index=False, encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
